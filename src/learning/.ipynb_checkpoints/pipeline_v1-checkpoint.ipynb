{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline params\n",
    "DATA_DIR = '../../data'\n",
    "BASE_DATASET =  f'{DATA_DIR}/hydropower_efficiency.discretized_labels.csv'\n",
    "\n",
    "SEED = 1\n",
    "FEATURE_SETS = {\n",
    "    'all': [\n",
    "        \"altitude_m\",\n",
    "        \"nearest_lake_dist_km\",\n",
    "        \"days_of_rain\",\n",
    "        \"rainfall\",\n",
    "        \"avg_daily_temp\",\n",
    "        \"min_daily_temp\",\n",
    "        \"max_daily_temp\",\n",
    "        \"sea_level_pressure\",\n",
    "        \"global_radiation\",\n",
    "        \"50m_gradient\",\n",
    "        \"100m_gradient\",\n",
    "        \"500m_gradient\",\n",
    "    ],\n",
    "    'all_selected': [\n",
    "        \"altitude_m\",\n",
    "        \"nearest_lake_dist_km\",\n",
    "        \"rainfall\",\n",
    "        \"avg_daily_temp\",\n",
    "        \"sea_level_pressure\",\n",
    "        \"global_radiation\",\n",
    "        \"50m_gradient\",\n",
    "        \"500m_gradient\",\n",
    "    ],\n",
    "    'precipitation': [\n",
    "        \"days_of_rain\",\n",
    "        \"sea_level_pressure\",\n",
    "        \"rainfall\",\n",
    "    ],\n",
    "    'precipitation_selected': [\n",
    "        \"sea_level_pressure\",\n",
    "        \"rainfall\",\n",
    "    ],\n",
    "    'geospatial': [\n",
    "        \"altitude_m\",\n",
    "        \"50m_gradient\",\n",
    "        \"100m_gradient\",\n",
    "        \"500m_gradient\",\n",
    "    ],\n",
    "    'geospatial_selected': [\n",
    "        \"altitude_m\",\n",
    "        \"50m_gradient\",\n",
    "        \"500m_gradient\",\n",
    "    ],\n",
    "    'geographic': [\n",
    "        \"nearest_lake_dist_km\",\n",
    "    ],\n",
    "    'geographic_selected': [\n",
    "        \"nearest_lake_dist_km\",\n",
    "    ],\n",
    "    'temperature': [\n",
    "        \"avg_daily_temp\",\n",
    "        \"min_daily_temp\",\n",
    "        \"max_daily_temp\",\n",
    "        \"global_radiation\",\n",
    "    ],\n",
    "    'temperature_selected': [\n",
    "        \"avg_daily_temp\",\n",
    "        \"global_radiation\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "DISPLAY_F1_ONLY = True\n",
    "TUNE_HYPER_PARAMS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and split dataset \n",
    "base_df = pd.read_csv(BASE_DATASET)\n",
    "base_df.drop('plant_id', axis=1, inplace=True)\n",
    "base_df.drop('type', axis=1, inplace=True)\n",
    "base_df = base_df[base_df['gwh_per_mm3'] < 10] \n",
    "\n",
    "X, y = base_df.drop('grade', axis=1), base_df['grade']\n",
    "X = X[FEATURE_SETS['all']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_train[FEATURE_SETS['all']] = scaler.fit_transform(X_train[FEATURE_SETS['all']])\n",
    "X_val[FEATURE_SETS['all']] = scaler.transform(X_val[FEATURE_SETS['all']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models + grid search params \n",
    "classifiers = {\n",
    "    'LR': LogisticRegression(class_weight='balanced'),\n",
    "    'RF': RandomForestClassifier(class_weight='balanced'),\n",
    "    'QDA': QuadraticDiscriminantAnalysis(),\n",
    "    'SVM': SVC(class_weight='balanced'),\n",
    "    'NN': MLPClassifier()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'LR': {\n",
    "        'class_weight': ['balanced'],\n",
    "        'multi_class': ['multinomial'],\n",
    "        'penalty': ['elasticnet'],\n",
    "        'solver': ['saga'],\n",
    "        'C': [0.001, 0.1, 1, 10],\n",
    "        'l1_ratio': [0, 0.25, 0.5, 0.75, 1],\n",
    "        'max_iter': [5000],\n",
    "        'random_state': [SEED]\n",
    "    },\n",
    "    'RF': {\n",
    "        'class_weight': ['balanced'],\n",
    "        'max_features': ['auto'],\n",
    "        'n_estimators': [500],\n",
    "        'max_depth': [None],\n",
    "        'min_samples_leaf': [1],\n",
    "        'n_jobs': [3],\n",
    "        'random_state': [SEED]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'class_weight': ['balanced'],\n",
    "        'kernel': ['poly', 'rbf'], \n",
    "        'C': [0.001, 0.1, 1, 10],\n",
    "        'degree': [3, 5, 10, 20]\n",
    "    },\n",
    "    'QDA': {\n",
    "        'reg_param': [0.001, 0.1, 1]\n",
    "    },\n",
    "    'NN': {\n",
    "        'hidden_layer_sizes': [(2,), (2, 2), (4, 4), (16,), (16, 32), (32, 64)],\n",
    "        'activation': ['logistic', 'relu'],\n",
    "        'alpha': [0.0001, 0.001],\n",
    "        'learning_rate': ['constant', 'invscaling'],\n",
    "        'max_iter': [5000],\n",
    "        'random_state': [SEED]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_tuned_clf(base_clf_name, tune, feature_set):\n",
    "    if tune:\n",
    "        clf = GridSearchCV(\n",
    "            classifiers[base_clf_name], \n",
    "            params[base_clf_name],\n",
    "            scoring='f1_macro'\n",
    "        )\n",
    "    else:\n",
    "        clf = classifiers[base_clf_name]\n",
    "    clf.fit(X_train[feature_set], y_train)\n",
    "\n",
    "    preds_train = clf.predict(X_train[feature_set])\n",
    "    preds_val = clf.predict(X_val[feature_set])\n",
    "    \n",
    "    train_f1 = f1_score(y_train, preds_train, average='macro')\n",
    "    val_f1 = f1_score(y_val, preds_val, average='macro')\n",
    "    \n",
    "    if DISPLAY_F1_ONLY:\n",
    "        print(f'== train f1: {train_f1}')\n",
    "        print(f'== val f1: {val_f1}')\n",
    "    else:\n",
    "        print(f'== train')\n",
    "        print(classification_report(y_train, preds_train))\n",
    "        print('==')\n",
    "\n",
    "        print(f'== val')\n",
    "        print(classification_report(y_val, preds_val))\n",
    "        print('==')\n",
    "    return train_f1, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== clf: LR | is_tuned: False | feature_set: all\n",
      "== train f1: 0.48430298981449216\n",
      "== val f1: 0.3676343922581953\n",
      "\n",
      "==== clf: LR | is_tuned: False | feature_set: all_selected\n",
      "== train f1: 0.47369780456306493\n",
      "== val f1: 0.3479643019998697\n",
      "\n",
      "==== clf: LR | is_tuned: True | feature_set: all\n",
      "== train f1: 0.430272536687631\n",
      "== val f1: 0.33350041771094396\n",
      "\n",
      "==== clf: LR | is_tuned: True | feature_set: all_selected\n",
      "== train f1: 0.4765662958048382\n",
      "== val f1: 0.3928626300719324\n",
      "\n",
      "==== clf: RF | is_tuned: False | feature_set: all\n",
      "== train f1: 1.0\n",
      "== val f1: 0.3819291819291819\n",
      "\n",
      "==== clf: RF | is_tuned: False | feature_set: all_selected\n",
      "== train f1: 1.0\n",
      "== val f1: 0.3637071651090342\n",
      "\n",
      "==== clf: RF | is_tuned: True | feature_set: all\n"
     ]
    }
   ],
   "source": [
    "# # Try all models\n",
    "# f1_scores = {'model': [], 'train_f1': [], 'val_f1': [], 'tuned': [], 'feature_set': []}\n",
    "# for base_clf_name in classifiers.keys(): # for every model\n",
    "#     for tuned in [False, True]: # try tuned & untuned version\n",
    "#         for feature_set in ['all', 'all_selected']: # try raw feature set & restricted feature set\n",
    "#             print(f'==== clf: {base_clf_name} | is_tuned: {tuned} | feature_set: {feature_set}')\n",
    "#             train_f1, val_f1 = eval_tuned_clf(base_clf_name, tuned, FEATURE_SETS[feature_set])\n",
    "#             print()\n",
    "\n",
    "#             f1_scores['model'].append(base_clf_name)\n",
    "#             f1_scores['train_f1'].append(train_f1)\n",
    "#             f1_scores['val_f1'].append(val_f1)\n",
    "#             f1_scores['tuned'].append(tuned)\n",
    "#             f1_scores['feature_set'].append(feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== train f1: 0.9170853884263325\n",
      "== val f1: 0.4393614303959132\n",
      "== train f1: 0.9098588993239871\n",
      "== val f1: 0.4114285714285714\n",
      "== train f1: 0.8916454298335034\n",
      "== val f1: 0.3844444444444444\n",
      "== train f1: 0.96897360131663\n",
      "== val f1: 0.34923076923076923\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component</th>\n",
       "      <th>F1 Score (Validation)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overall</td>\n",
       "      <td>0.439361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Temperature Features</td>\n",
       "      <td>0.411429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geographic Features</td>\n",
       "      <td>0.384444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geospatial Features</td>\n",
       "      <td>0.349231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Component  F1 Score (Validation)\n",
       "0               Overall               0.439361\n",
       "1  Temperature Features               0.411429\n",
       "2   Geographic Features               0.384444\n",
       "3   Geospatial Features               0.349231"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ablative analysis\n",
    "component_performance = {'Component': [], 'F1 Score (Validation)': []}\n",
    "\n",
    "component_performance['Component'].append('Overall')\n",
    "component_performance['F1 Score (Validation)'].append(\n",
    "    eval_tuned_clf(\n",
    "        'RF', \n",
    "        True,\n",
    "        FEATURE_SETS['all_selected']\n",
    "    )[1]\n",
    ")\n",
    "\n",
    "component_performance['Component'].append('Temperature Features')\n",
    "component_performance['F1 Score (Validation)'].append(\n",
    "    eval_tuned_clf(\n",
    "        'RF', \n",
    "        True,\n",
    "        FEATURE_SETS['precipitation_selected'] + FEATURE_SETS['geospatial_selected'] + FEATURE_SETS['geographic_selected']\n",
    "    )[1]\n",
    ")\n",
    "\n",
    "component_performance['Component'].append('Geographic Features')\n",
    "component_performance['F1 Score (Validation)'].append(\n",
    "    eval_tuned_clf(\n",
    "        'RF', \n",
    "        True,\n",
    "        FEATURE_SETS['precipitation_selected'] + FEATURE_SETS['geospatial_selected']\n",
    "    )[1]\n",
    ")\n",
    "\n",
    "component_performance['Component'].append('Geospatial Features')\n",
    "component_performance['F1 Score (Validation)'].append(\n",
    "    eval_tuned_clf(\n",
    "        'RF', \n",
    "        True,\n",
    "        FEATURE_SETS['precipitation_selected']\n",
    "    )[1]\n",
    ")\n",
    "\n",
    "pd.DataFrame.from_dict(component_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final_train = pd.concat([X_train, X_val])\n",
    "y_final_train = pd.concat([y_train, y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.56      0.61        54\n",
      "           1       0.32      0.52      0.39        25\n",
      "           2       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.50        86\n",
      "   macro avg       0.33      0.36      0.33        86\n",
      "weighted avg       0.51      0.50      0.50        86\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# baseline & raw feature set\n",
    "clf1 = RandomForestClassifier(class_weight='balanced', random_state=0)\n",
    "clf1.fit(X_final_train[FEATURE_SETS['all']], y_final_train)\n",
    "preds1 = clf1.predict(X_test[FEATURE_SETS['all']]) \n",
    "print(classification_report(y_test, preds1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.87      0.74        54\n",
      "           1       0.38      0.20      0.26        25\n",
      "           2       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.60        86\n",
      "   macro avg       0.34      0.36      0.33        86\n",
      "weighted avg       0.52      0.60      0.54        86\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# hyperparams tuned & raw feature set\n",
    "clf2 = GridSearchCV(\n",
    "    classifiers['RF'], \n",
    "    params['RF'],\n",
    "    scoring='f1_macro'\n",
    ")\n",
    "clf2.fit(X_final_train[FEATURE_SETS['all']], y_final_train)\n",
    "preds2 = clf2.predict(X_test[FEATURE_SETS['all']])\n",
    "print(classification_report(y_test, preds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.87      0.73        54\n",
      "           1       0.27      0.12      0.17        25\n",
      "           2       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.58        86\n",
      "   macro avg       0.30      0.33      0.30        86\n",
      "weighted avg       0.47      0.58      0.51        86\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# hyperparams tuned & restricted feature set \n",
    "clf3 = GridSearchCV(\n",
    "    classifiers['RF'], \n",
    "    params['RF'],\n",
    "    scoring='f1_macro'\n",
    ")\n",
    "clf3.fit(X_final_train[FEATURE_SETS['all_selected']], y_final_train)\n",
    "preds3 = clf3.predict(X_test[FEATURE_SETS['all_selected']])\n",
    "print(classification_report(y_test, preds3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227    0\n",
       "208    0\n",
       "164    0\n",
       "277    0\n",
       "62     0\n",
       "      ..\n",
       "291    0\n",
       "245    0\n",
       "426    0\n",
       "312    1\n",
       "80     0\n",
       "Name: grade, Length: 86, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[47,  7,  0],\n",
       "       [22,  3,  0],\n",
       "       [ 6,  1,  0]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, preds3, labels=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>altitude_m</th>\n",
       "      <th>nearest_lake_dist_km</th>\n",
       "      <th>days_of_rain</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>avg_daily_temp</th>\n",
       "      <th>min_daily_temp</th>\n",
       "      <th>max_daily_temp</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>global_radiation</th>\n",
       "      <th>50m_gradient</th>\n",
       "      <th>100m_gradient</th>\n",
       "      <th>500m_gradient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.101568</td>\n",
       "      <td>0.082689</td>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.123974</td>\n",
       "      <td>0.160250</td>\n",
       "      <td>0.109352</td>\n",
       "      <td>0.199800</td>\n",
       "      <td>0.988236</td>\n",
       "      <td>0.452508</td>\n",
       "      <td>0.107399</td>\n",
       "      <td>0.092715</td>\n",
       "      <td>0.013918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0.338095</td>\n",
       "      <td>0.047371</td>\n",
       "      <td>0.100917</td>\n",
       "      <td>0.164450</td>\n",
       "      <td>0.440200</td>\n",
       "      <td>0.394930</td>\n",
       "      <td>0.464212</td>\n",
       "      <td>0.996184</td>\n",
       "      <td>0.712485</td>\n",
       "      <td>0.304296</td>\n",
       "      <td>0.322697</td>\n",
       "      <td>0.260212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.470857</td>\n",
       "      <td>0.019447</td>\n",
       "      <td>0.477064</td>\n",
       "      <td>0.492799</td>\n",
       "      <td>0.199337</td>\n",
       "      <td>0.266839</td>\n",
       "      <td>0.187065</td>\n",
       "      <td>0.989758</td>\n",
       "      <td>0.388188</td>\n",
       "      <td>0.337709</td>\n",
       "      <td>0.358820</td>\n",
       "      <td>0.231467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.058667</td>\n",
       "      <td>0.078136</td>\n",
       "      <td>0.477064</td>\n",
       "      <td>0.365225</td>\n",
       "      <td>0.330356</td>\n",
       "      <td>0.372033</td>\n",
       "      <td>0.333326</td>\n",
       "      <td>0.987712</td>\n",
       "      <td>0.451133</td>\n",
       "      <td>0.455847</td>\n",
       "      <td>0.446117</td>\n",
       "      <td>0.275340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.014160</td>\n",
       "      <td>0.172460</td>\n",
       "      <td>0.477064</td>\n",
       "      <td>0.353713</td>\n",
       "      <td>0.286924</td>\n",
       "      <td>0.332251</td>\n",
       "      <td>0.279623</td>\n",
       "      <td>0.987483</td>\n",
       "      <td>0.429590</td>\n",
       "      <td>0.516706</td>\n",
       "      <td>0.491872</td>\n",
       "      <td>0.423601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.136058</td>\n",
       "      <td>0.008697</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>0.110122</td>\n",
       "      <td>0.678621</td>\n",
       "      <td>0.616651</td>\n",
       "      <td>0.691280</td>\n",
       "      <td>0.996206</td>\n",
       "      <td>0.766040</td>\n",
       "      <td>0.085919</td>\n",
       "      <td>0.072848</td>\n",
       "      <td>0.018911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.195021</td>\n",
       "      <td>0.064391</td>\n",
       "      <td>0.477064</td>\n",
       "      <td>0.270467</td>\n",
       "      <td>0.198860</td>\n",
       "      <td>0.233351</td>\n",
       "      <td>0.220688</td>\n",
       "      <td>0.988122</td>\n",
       "      <td>0.460388</td>\n",
       "      <td>0.514320</td>\n",
       "      <td>0.467188</td>\n",
       "      <td>0.378215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0.011370</td>\n",
       "      <td>0.059963</td>\n",
       "      <td>0.403670</td>\n",
       "      <td>0.151470</td>\n",
       "      <td>0.360016</td>\n",
       "      <td>0.382319</td>\n",
       "      <td>0.354182</td>\n",
       "      <td>0.988394</td>\n",
       "      <td>0.477429</td>\n",
       "      <td>0.137232</td>\n",
       "      <td>0.118603</td>\n",
       "      <td>0.059909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.140496</td>\n",
       "      <td>0.341453</td>\n",
       "      <td>0.183486</td>\n",
       "      <td>0.139820</td>\n",
       "      <td>0.780165</td>\n",
       "      <td>0.777796</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.996702</td>\n",
       "      <td>0.827515</td>\n",
       "      <td>0.211217</td>\n",
       "      <td>0.229380</td>\n",
       "      <td>0.095008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.211632</td>\n",
       "      <td>0.147319</td>\n",
       "      <td>0.477064</td>\n",
       "      <td>0.197886</td>\n",
       "      <td>0.234825</td>\n",
       "      <td>0.239500</td>\n",
       "      <td>0.263876</td>\n",
       "      <td>0.989531</td>\n",
       "      <td>0.450451</td>\n",
       "      <td>0.126492</td>\n",
       "      <td>0.115593</td>\n",
       "      <td>0.078064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     altitude_m  nearest_lake_dist_km  days_of_rain  rainfall  avg_daily_temp  \\\n",
       "272    0.101568              0.082689      0.495413  0.123974        0.160250   \n",
       "389    0.338095              0.047371      0.100917  0.164450        0.440200   \n",
       "42     0.470857              0.019447      0.477064  0.492799        0.199337   \n",
       "55     0.058667              0.078136      0.477064  0.365225        0.330356   \n",
       "178    0.014160              0.172460      0.477064  0.353713        0.286924   \n",
       "..          ...                   ...           ...       ...             ...   \n",
       "118    0.136058              0.008697      0.311927  0.110122        0.678621   \n",
       "190    0.195021              0.064391      0.477064  0.270467        0.198860   \n",
       "347    0.011370              0.059963      0.403670  0.151470        0.360016   \n",
       "20     0.140496              0.341453      0.183486  0.139820        0.780165   \n",
       "271    0.211632              0.147319      0.477064  0.197886        0.234825   \n",
       "\n",
       "     min_daily_temp  max_daily_temp  sea_level_pressure  global_radiation  \\\n",
       "272        0.109352        0.199800            0.988236          0.452508   \n",
       "389        0.394930        0.464212            0.996184          0.712485   \n",
       "42         0.266839        0.187065            0.989758          0.388188   \n",
       "55         0.372033        0.333326            0.987712          0.451133   \n",
       "178        0.332251        0.279623            0.987483          0.429590   \n",
       "..              ...             ...                 ...               ...   \n",
       "118        0.616651        0.691280            0.996206          0.766040   \n",
       "190        0.233351        0.220688            0.988122          0.460388   \n",
       "347        0.382319        0.354182            0.988394          0.477429   \n",
       "20         0.777796        0.738318            0.996702          0.827515   \n",
       "271        0.239500        0.263876            0.989531          0.450451   \n",
       "\n",
       "     50m_gradient  100m_gradient  500m_gradient  \n",
       "272      0.107399       0.092715       0.013918  \n",
       "389      0.304296       0.322697       0.260212  \n",
       "42       0.337709       0.358820       0.231467  \n",
       "55       0.455847       0.446117       0.275340  \n",
       "178      0.516706       0.491872       0.423601  \n",
       "..            ...            ...            ...  \n",
       "118      0.085919       0.072848       0.018911  \n",
       "190      0.514320       0.467188       0.378215  \n",
       "347      0.137232       0.118603       0.059909  \n",
       "20       0.211217       0.229380       0.095008  \n",
       "271      0.126492       0.115593       0.078064  \n",
       "\n",
       "[275 rows x 12 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272    0\n",
       "389    0\n",
       "42     0\n",
       "55     2\n",
       "178    2\n",
       "      ..\n",
       "118    1\n",
       "190    1\n",
       "347    1\n",
       "20     0\n",
       "271    0\n",
       "Name: grade, Length: 275, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curve\n",
    "clf = RandomForestClassifier(class_weight='balanced', random_state=0)\n",
    "clf.fit(X_train[FEATURE_SETS['all_selected']], y_train)\n",
    "f1_score_train = f1_score(\n",
    "    clf.predict(X_train[FEATURE_SETS['all_selected']]), \n",
    "    y_train, \n",
    "    average='macro'\n",
    ")\n",
    "f1_score_val = f1_score(\n",
    "    clf.predict(X_val[FEATURE_SETS['all_selected']]), \n",
    "    y_val, \n",
    "    average='macro'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
